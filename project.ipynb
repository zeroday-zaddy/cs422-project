{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model using MultiOutput Classifier  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect: relaxed\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.44      1.00      0.61       418\n",
      "        100%       0.00      0.00      0.00        68\n",
      "         12%       0.00      0.00      0.00         1\n",
      "         16%       0.00      0.00      0.00         1\n",
      "         18%       0.00      0.00      0.00         2\n",
      "         20%       0.00      0.00      0.00         1\n",
      "         22%       0.00      0.00      0.00         3\n",
      "         23%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         7\n",
      "         27%       0.00      0.00      0.00         2\n",
      "         28%       0.00      0.00      0.00         3\n",
      "         30%       0.00      0.00      0.00         1\n",
      "         31%       0.00      0.00      0.00         1\n",
      "         32%       0.00      0.00      0.00         1\n",
      "         33%       0.00      0.00      0.00        10\n",
      "         35%       0.00      0.00      0.00         3\n",
      "         36%       0.00      0.00      0.00         1\n",
      "         37%       0.00      0.00      0.00         7\n",
      "         38%       0.00      0.00      0.00         2\n",
      "         39%       0.00      0.00      0.00         3\n",
      "         40%       0.00      0.00      0.00        14\n",
      "         41%       0.00      0.00      0.00         8\n",
      "         42%       0.00      0.00      0.00         9\n",
      "         43%       0.00      0.00      0.00         2\n",
      "         44%       0.00      0.00      0.00         8\n",
      "         45%       0.00      0.00      0.00        12\n",
      "         46%       0.00      0.00      0.00         5\n",
      "         47%       0.00      0.00      0.00         9\n",
      "         48%       0.00      0.00      0.00         8\n",
      "         49%       0.00      0.00      0.00         2\n",
      "         50%       0.00      0.00      0.00        49\n",
      "         51%       0.00      0.00      0.00         4\n",
      "         52%       0.00      0.00      0.00        11\n",
      "         53%       0.00      0.00      0.00         5\n",
      "         54%       0.00      0.00      0.00         4\n",
      "         55%       0.00      0.00      0.00        17\n",
      "         56%       0.00      0.00      0.00         6\n",
      "         57%       0.00      0.00      0.00        15\n",
      "         58%       0.00      0.00      0.00        10\n",
      "         59%       0.00      0.00      0.00         7\n",
      "         60%       0.00      0.00      0.00        15\n",
      "         61%       0.00      0.00      0.00         6\n",
      "         62%       0.00      0.00      0.00         8\n",
      "         63%       0.00      0.00      0.00         4\n",
      "         64%       0.00      0.00      0.00        10\n",
      "         65%       0.00      0.00      0.00         5\n",
      "         66%       0.00      0.00      0.00        32\n",
      "         67%       0.00      0.00      0.00         7\n",
      "         68%       0.00      0.00      0.00         9\n",
      "         69%       0.00      0.00      0.00        11\n",
      "         70%       0.00      0.00      0.00        10\n",
      "         71%       0.00      0.00      0.00         8\n",
      "         72%       0.00      0.00      0.00         7\n",
      "         73%       0.00      0.00      0.00         8\n",
      "         74%       0.00      0.00      0.00         3\n",
      "         75%       0.00      0.00      0.00        17\n",
      "         76%       0.00      0.00      0.00         3\n",
      "         77%       0.00      0.00      0.00        11\n",
      "         78%       0.00      0.00      0.00         1\n",
      "         79%       0.00      0.00      0.00         1\n",
      "         80%       0.00      0.00      0.00        12\n",
      "         81%       0.00      0.00      0.00         5\n",
      "         82%       0.00      0.00      0.00         3\n",
      "         83%       0.00      0.00      0.00         5\n",
      "         84%       0.00      0.00      0.00         1\n",
      "         85%       0.00      0.00      0.00         2\n",
      "         87%       0.00      0.00      0.00         2\n",
      "         88%       0.00      0.00      0.00         2\n",
      "         90%       0.00      0.00      0.00         3\n",
      "         94%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.44       953\n",
      "   macro avg       0.01      0.01      0.01       953\n",
      "weighted avg       0.19      0.44      0.27       953\n",
      "\n",
      "==================================================\n",
      "Effect: happy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.41      1.00      0.58       389\n",
      "        100%       0.00      0.00      0.00        49\n",
      "         11%       0.00      0.00      0.00         1\n",
      "         12%       0.00      0.00      0.00         1\n",
      "         14%       0.00      0.00      0.00         1\n",
      "         15%       0.00      0.00      0.00         1\n",
      "         16%       0.00      0.00      0.00         1\n",
      "         18%       0.00      0.00      0.00         1\n",
      "         20%       0.00      0.00      0.00         2\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         6\n",
      "         27%       0.00      0.00      0.00         2\n",
      "         28%       0.00      0.00      0.00         4\n",
      "         29%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00         2\n",
      "         31%       0.00      0.00      0.00         3\n",
      "         32%       0.00      0.00      0.00         1\n",
      "         33%       0.00      0.00      0.00        16\n",
      "         34%       0.00      0.00      0.00         2\n",
      "         35%       0.00      0.00      0.00         7\n",
      "         36%       0.00      0.00      0.00         4\n",
      "         37%       0.00      0.00      0.00         6\n",
      "         38%       0.00      0.00      0.00         5\n",
      "         39%       0.00      0.00      0.00         2\n",
      "         40%       0.00      0.00      0.00        18\n",
      "         41%       0.00      0.00      0.00         7\n",
      "         42%       0.00      0.00      0.00        10\n",
      "         43%       0.00      0.00      0.00         7\n",
      "         44%       0.00      0.00      0.00        10\n",
      "         45%       0.00      0.00      0.00         6\n",
      "         46%       0.00      0.00      0.00         7\n",
      "         47%       0.00      0.00      0.00         8\n",
      "         48%       0.00      0.00      0.00         7\n",
      "         49%       0.00      0.00      0.00         1\n",
      "         50%       0.33      0.03      0.06        66\n",
      "         51%       0.00      0.00      0.00         5\n",
      "         52%       0.00      0.00      0.00        19\n",
      "         53%       0.00      0.00      0.00        13\n",
      "         54%       0.00      0.00      0.00        18\n",
      "         55%       0.00      0.00      0.00        20\n",
      "         56%       0.00      0.00      0.00        10\n",
      "         57%       0.00      0.00      0.00        11\n",
      "         58%       0.00      0.00      0.00        12\n",
      "         59%       0.00      0.00      0.00        12\n",
      "         60%       0.00      0.00      0.00        32\n",
      "         61%       0.00      0.00      0.00        12\n",
      "         62%       0.00      0.00      0.00        18\n",
      "         63%       0.00      0.00      0.00         6\n",
      "         64%       0.00      0.00      0.00         9\n",
      "         65%       0.00      0.00      0.00         3\n",
      "         66%       0.00      0.00      0.00        22\n",
      "         67%       0.00      0.00      0.00         1\n",
      "         68%       0.00      0.00      0.00         7\n",
      "         69%       0.00      0.00      0.00         8\n",
      "         70%       0.00      0.00      0.00         3\n",
      "         71%       0.00      0.00      0.00         8\n",
      "         72%       0.00      0.00      0.00         5\n",
      "         73%       0.00      0.00      0.00         4\n",
      "         75%       0.00      0.00      0.00        21\n",
      "         76%       0.00      0.00      0.00         1\n",
      "         77%       0.00      0.00      0.00         3\n",
      "         78%       0.00      0.00      0.00         3\n",
      "         80%       0.00      0.00      0.00         5\n",
      "         81%       0.00      0.00      0.00         2\n",
      "         85%       0.00      0.00      0.00         2\n",
      "         88%       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.41       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.19      0.41      0.24       953\n",
      "\n",
      "==================================================\n",
      "Effect: euphoric\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.51      1.00      0.68       489\n",
      "        100%       0.00      0.00      0.00        32\n",
      "         12%       0.00      0.00      0.00         1\n",
      "         16%       0.00      0.00      0.00         1\n",
      "         18%       0.00      0.00      0.00         2\n",
      "         19%       0.00      0.00      0.00         1\n",
      "         20%       0.00      0.00      0.00         4\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         3\n",
      "         28%       0.00      0.00      0.00         6\n",
      "         29%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00         2\n",
      "         31%       0.00      0.00      0.00         3\n",
      "         33%       0.00      0.00      0.00        15\n",
      "         34%       0.00      0.00      0.00         2\n",
      "         35%       0.00      0.00      0.00         9\n",
      "         36%       0.00      0.00      0.00         4\n",
      "         37%       0.00      0.00      0.00        10\n",
      "         38%       0.00      0.00      0.00         5\n",
      "         39%       0.00      0.00      0.00         4\n",
      "         40%       0.00      0.00      0.00        22\n",
      "         41%       0.00      0.00      0.00        22\n",
      "         42%       0.00      0.00      0.00        15\n",
      "         43%       0.00      0.00      0.00        10\n",
      "         44%       0.00      0.00      0.00        19\n",
      "         45%       0.00      0.00      0.00         9\n",
      "         46%       0.00      0.00      0.00        10\n",
      "         47%       0.00      0.00      0.00        16\n",
      "         48%       0.00      0.00      0.00         8\n",
      "         49%       0.00      0.00      0.00         7\n",
      "         50%       0.00      0.00      0.00        53\n",
      "         51%       0.00      0.00      0.00         6\n",
      "         52%       0.00      0.00      0.00        10\n",
      "         53%       0.00      0.00      0.00        11\n",
      "         54%       0.00      0.00      0.00        18\n",
      "         55%       0.00      0.00      0.00        15\n",
      "         56%       0.00      0.00      0.00         7\n",
      "         57%       0.00      0.00      0.00         7\n",
      "         58%       0.00      0.00      0.00         6\n",
      "         59%       0.00      0.00      0.00         4\n",
      "         60%       0.00      0.00      0.00        15\n",
      "         61%       0.00      0.00      0.00         2\n",
      "         62%       0.00      0.00      0.00         3\n",
      "         63%       0.00      0.00      0.00         1\n",
      "         64%       0.00      0.00      0.00         2\n",
      "         65%       0.00      0.00      0.00         5\n",
      "         66%       0.00      0.00      0.00        23\n",
      "         67%       0.00      0.00      0.00         3\n",
      "         68%       0.00      0.00      0.00         1\n",
      "         69%       0.00      0.00      0.00         2\n",
      "         70%       0.00      0.00      0.00         1\n",
      "         71%       0.00      0.00      0.00         4\n",
      "         72%       0.00      0.00      0.00         1\n",
      "         73%       0.00      0.00      0.00         1\n",
      "         75%       0.00      0.00      0.00         9\n",
      "         76%       0.00      0.00      0.00         1\n",
      "         77%       0.00      0.00      0.00         2\n",
      "         79%       0.00      0.00      0.00         1\n",
      "         81%       0.00      0.00      0.00         1\n",
      "         83%       0.00      0.00      0.00         3\n",
      "         85%       0.00      0.00      0.00         1\n",
      "         90%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.26      0.51      0.35       953\n",
      "\n",
      "==================================================\n",
      "Effect: uplifted\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.49      1.00      0.65       464\n",
      "        100%       0.00      0.00      0.00        30\n",
      "         14%       0.00      0.00      0.00         2\n",
      "         16%       0.00      0.00      0.00         4\n",
      "         19%       0.00      0.00      0.00         1\n",
      "         20%       0.00      0.00      0.00        11\n",
      "         21%       0.00      0.00      0.00         1\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         23%       0.00      0.00      0.00         3\n",
      "         25%       0.00      0.00      0.00        10\n",
      "         26%       0.00      0.00      0.00         2\n",
      "         27%       0.00      0.00      0.00         4\n",
      "         28%       0.00      0.00      0.00         8\n",
      "         29%       0.00      0.00      0.00         3\n",
      "         30%       0.00      0.00      0.00         8\n",
      "         31%       0.00      0.00      0.00         6\n",
      "         32%       0.00      0.00      0.00         9\n",
      "         33%       0.00      0.00      0.00        21\n",
      "         34%       0.00      0.00      0.00         3\n",
      "         35%       0.00      0.00      0.00         9\n",
      "         36%       0.00      0.00      0.00         6\n",
      "         37%       0.00      0.00      0.00        13\n",
      "         38%       0.00      0.00      0.00         7\n",
      "         39%       0.00      0.00      0.00         3\n",
      "         40%       0.00      0.00      0.00        25\n",
      "         41%       0.00      0.00      0.00        11\n",
      "         42%       0.00      0.00      0.00        14\n",
      "         43%       0.00      0.00      0.00         7\n",
      "         44%       0.00      0.00      0.00        18\n",
      "         45%       0.00      0.00      0.00        18\n",
      "         46%       0.00      0.00      0.00         5\n",
      "         47%       0.00      0.00      0.00        12\n",
      "         48%       0.00      0.00      0.00         8\n",
      "         49%       0.00      0.00      0.00         2\n",
      "         50%       0.00      0.00      0.00        62\n",
      "         51%       0.00      0.00      0.00        12\n",
      "         52%       0.00      0.00      0.00        11\n",
      "         53%       0.00      0.00      0.00         9\n",
      "         54%       0.00      0.00      0.00         8\n",
      "         55%       0.00      0.00      0.00        16\n",
      "         56%       0.00      0.00      0.00         3\n",
      "         57%       0.00      0.00      0.00         8\n",
      "         58%       0.00      0.00      0.00         4\n",
      "         59%       0.00      0.00      0.00         3\n",
      "          6%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         8\n",
      "         61%       0.00      0.00      0.00         3\n",
      "         62%       0.00      0.00      0.00         3\n",
      "         63%       0.00      0.00      0.00         1\n",
      "         64%       0.00      0.00      0.00         2\n",
      "         65%       0.00      0.00      0.00         3\n",
      "         66%       0.00      0.00      0.00        24\n",
      "         67%       0.00      0.00      0.00         1\n",
      "         68%       0.00      0.00      0.00         1\n",
      "         70%       0.00      0.00      0.00         1\n",
      "         71%       0.00      0.00      0.00         2\n",
      "         72%       0.00      0.00      0.00         2\n",
      "         73%       0.00      0.00      0.00         1\n",
      "         74%       0.00      0.00      0.00         1\n",
      "         75%       0.00      0.00      0.00         7\n",
      "         80%       0.00      0.00      0.00         4\n",
      "         81%       0.00      0.00      0.00         1\n",
      "         83%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.49       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.24      0.49      0.32       953\n",
      "\n",
      "==================================================\n",
      "Effect: sleepy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.80      1.00      0.89       759\n",
      "        100%       0.00      0.00      0.00        13\n",
      "         12%       0.00      0.00      0.00         1\n",
      "         14%       0.00      0.00      0.00         1\n",
      "         16%       0.00      0.00      0.00         6\n",
      "         18%       0.00      0.00      0.00         2\n",
      "         20%       0.00      0.00      0.00         2\n",
      "         21%       0.00      0.00      0.00         1\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         24%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00        10\n",
      "         26%       0.00      0.00      0.00         2\n",
      "         27%       0.00      0.00      0.00         2\n",
      "         28%       0.00      0.00      0.00         4\n",
      "         29%       0.00      0.00      0.00         4\n",
      "         30%       0.00      0.00      0.00         5\n",
      "         31%       0.00      0.00      0.00         5\n",
      "         32%       0.00      0.00      0.00         3\n",
      "         33%       0.00      0.00      0.00        15\n",
      "         34%       0.00      0.00      0.00         2\n",
      "         35%       0.00      0.00      0.00         5\n",
      "         36%       0.00      0.00      0.00         6\n",
      "         37%       0.00      0.00      0.00         2\n",
      "         38%       0.00      0.00      0.00         4\n",
      "         39%       0.00      0.00      0.00         3\n",
      "         40%       0.00      0.00      0.00         6\n",
      "         41%       0.00      0.00      0.00         5\n",
      "         42%       0.00      0.00      0.00         6\n",
      "         43%       0.00      0.00      0.00         2\n",
      "         44%       0.00      0.00      0.00        11\n",
      "         45%       0.00      0.00      0.00         5\n",
      "         46%       0.00      0.00      0.00         3\n",
      "         47%       0.00      0.00      0.00         1\n",
      "         48%       0.00      0.00      0.00         1\n",
      "         49%       0.00      0.00      0.00         1\n",
      "         50%       0.00      0.00      0.00        27\n",
      "         51%       0.00      0.00      0.00         2\n",
      "         53%       0.00      0.00      0.00         1\n",
      "         54%       0.00      0.00      0.00         1\n",
      "         55%       0.00      0.00      0.00         4\n",
      "         56%       0.00      0.00      0.00         3\n",
      "         57%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         1\n",
      "         63%       0.00      0.00      0.00         4\n",
      "         66%       0.00      0.00      0.00         5\n",
      "         70%       0.00      0.00      0.00         1\n",
      "          8%       0.00      0.00      0.00         1\n",
      "         80%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.80       953\n",
      "   macro avg       0.02      0.02      0.02       953\n",
      "weighted avg       0.63      0.80      0.71       953\n",
      "\n",
      "==================================================\n",
      "Effect: dry_mouth\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.51      1.00      0.67       482\n",
      "         10%       0.00      0.00      0.00        13\n",
      "        100%       0.00      0.00      0.00         8\n",
      "         11%       0.00      0.00      0.00        12\n",
      "         12%       0.00      0.00      0.00        11\n",
      "         13%       0.00      0.00      0.00         7\n",
      "         14%       0.00      0.00      0.00        19\n",
      "         15%       0.00      0.00      0.00        14\n",
      "         16%       0.00      0.00      0.00        14\n",
      "         17%       0.00      0.00      0.00        13\n",
      "         18%       0.00      0.00      0.00        21\n",
      "         19%       0.00      0.00      0.00        12\n",
      "          2%       0.00      0.00      0.00         1\n",
      "         20%       0.00      0.00      0.00        26\n",
      "         21%       0.00      0.00      0.00        13\n",
      "         22%       0.00      0.00      0.00        14\n",
      "         23%       0.00      0.00      0.00        10\n",
      "         24%       0.00      0.00      0.00        13\n",
      "         25%       0.00      0.00      0.00        34\n",
      "         26%       0.00      0.00      0.00        11\n",
      "         27%       0.00      0.00      0.00        14\n",
      "         28%       0.00      0.00      0.00        17\n",
      "         29%       0.00      0.00      0.00         5\n",
      "          3%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00        14\n",
      "         31%       0.00      0.00      0.00         7\n",
      "         32%       0.00      0.00      0.00        11\n",
      "         33%       0.00      0.00      0.00        25\n",
      "         34%       0.00      0.00      0.00         4\n",
      "         35%       0.00      0.00      0.00         6\n",
      "         36%       0.00      0.00      0.00         8\n",
      "         37%       0.00      0.00      0.00         3\n",
      "         38%       0.00      0.00      0.00         7\n",
      "         39%       0.00      0.00      0.00         1\n",
      "          4%       0.00      0.00      0.00         4\n",
      "         40%       0.00      0.00      0.00         5\n",
      "         41%       0.00      0.00      0.00         4\n",
      "         42%       0.00      0.00      0.00         3\n",
      "         44%       0.00      0.00      0.00         2\n",
      "         45%       0.00      0.00      0.00         1\n",
      "         46%       0.00      0.00      0.00         2\n",
      "          5%       0.00      0.00      0.00         2\n",
      "         50%       0.00      0.00      0.00        28\n",
      "         52%       0.00      0.00      0.00         1\n",
      "         54%       0.00      0.00      0.00         1\n",
      "         55%       0.00      0.00      0.00         1\n",
      "          6%       0.00      0.00      0.00         4\n",
      "         60%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         1\n",
      "          7%       0.00      0.00      0.00         8\n",
      "          8%       0.00      0.00      0.00         4\n",
      "         80%       0.00      0.00      0.00         2\n",
      "          9%       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.51       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.26      0.51      0.34       953\n",
      "\n",
      "==================================================\n",
      "Effect: dry_eyes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.56      1.00      0.72       537\n",
      "         10%       0.00      0.00      0.00        23\n",
      "        100%       0.00      0.00      0.00         2\n",
      "         11%       0.00      0.00      0.00        32\n",
      "         12%       0.00      0.00      0.00        26\n",
      "         13%       0.00      0.00      0.00        24\n",
      "         14%       0.00      0.00      0.00        28\n",
      "         15%       0.00      0.00      0.00         9\n",
      "         16%       0.00      0.00      0.00        20\n",
      "         17%       0.00      0.00      0.00        13\n",
      "         18%       0.00      0.00      0.00         8\n",
      "         19%       0.00      0.00      0.00         8\n",
      "          2%       0.00      0.00      0.00         8\n",
      "         20%       0.00      0.00      0.00        22\n",
      "         21%       0.00      0.00      0.00         5\n",
      "         22%       0.00      0.00      0.00         7\n",
      "         23%       0.00      0.00      0.00         6\n",
      "         24%       0.00      0.00      0.00         3\n",
      "         25%       0.00      0.00      0.00        17\n",
      "         26%       0.00      0.00      0.00         3\n",
      "         27%       0.00      0.00      0.00         3\n",
      "         28%       0.00      0.00      0.00         4\n",
      "         29%       0.00      0.00      0.00         1\n",
      "          3%       0.00      0.00      0.00         2\n",
      "         30%       0.00      0.00      0.00         1\n",
      "         32%       0.00      0.00      0.00         1\n",
      "         33%       0.00      0.00      0.00        15\n",
      "         35%       0.00      0.00      0.00         2\n",
      "         37%       0.00      0.00      0.00         1\n",
      "          4%       0.00      0.00      0.00        11\n",
      "         40%       0.00      0.00      0.00         5\n",
      "         41%       0.00      0.00      0.00         1\n",
      "         42%       0.00      0.00      0.00         1\n",
      "          5%       0.00      0.00      0.00        15\n",
      "         50%       0.00      0.00      0.00        11\n",
      "          6%       0.00      0.00      0.00        17\n",
      "         60%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         1\n",
      "          7%       0.00      0.00      0.00        22\n",
      "          8%       0.00      0.00      0.00        20\n",
      "          9%       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.56       953\n",
      "   macro avg       0.01      0.02      0.02       953\n",
      "weighted avg       0.32      0.56      0.41       953\n",
      "\n",
      "==================================================\n",
      "Effect: dizzy\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.69      1.00      0.82       659\n",
      "          1%       0.00      0.00      0.00        10\n",
      "         10%       0.00      0.00      0.00        17\n",
      "        100%       0.00      0.00      0.00         1\n",
      "         11%       0.00      0.00      0.00        12\n",
      "         12%       0.00      0.00      0.00         7\n",
      "         13%       0.00      0.00      0.00         2\n",
      "         14%       0.00      0.00      0.00         5\n",
      "         15%       0.00      0.00      0.00         1\n",
      "         16%       0.00      0.00      0.00         9\n",
      "         17%       0.00      0.00      0.00         3\n",
      "         18%       0.00      0.00      0.00         3\n",
      "          2%       0.00      0.00      0.00        15\n",
      "         20%       0.00      0.00      0.00         9\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         4\n",
      "          3%       0.00      0.00      0.00        28\n",
      "         30%       0.00      0.00      0.00         1\n",
      "         33%       0.00      0.00      0.00         6\n",
      "          4%       0.00      0.00      0.00        31\n",
      "         40%       0.00      0.00      0.00         2\n",
      "          5%       0.00      0.00      0.00        32\n",
      "         50%       0.00      0.00      0.00         2\n",
      "          6%       0.00      0.00      0.00        31\n",
      "          7%       0.00      0.00      0.00        26\n",
      "          8%       0.00      0.00      0.00        19\n",
      "          9%       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.69       953\n",
      "   macro avg       0.03      0.04      0.03       953\n",
      "weighted avg       0.48      0.69      0.57       953\n",
      "\n",
      "==================================================\n",
      "Effect: paranoid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.75      1.00      0.86       715\n",
      "          1%       0.00      0.00      0.00        14\n",
      "         10%       0.00      0.00      0.00        12\n",
      "        100%       0.00      0.00      0.00         3\n",
      "         11%       0.00      0.00      0.00         7\n",
      "         12%       0.00      0.00      0.00         7\n",
      "         14%       0.00      0.00      0.00         6\n",
      "         15%       0.00      0.00      0.00         3\n",
      "         16%       0.00      0.00      0.00         3\n",
      "         17%       0.00      0.00      0.00         1\n",
      "         18%       0.00      0.00      0.00         2\n",
      "          2%       0.00      0.00      0.00        19\n",
      "         20%       0.00      0.00      0.00         9\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         23%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         2\n",
      "         28%       0.00      0.00      0.00         1\n",
      "          3%       0.00      0.00      0.00        14\n",
      "         33%       0.00      0.00      0.00         3\n",
      "          4%       0.00      0.00      0.00        33\n",
      "          5%       0.00      0.00      0.00        34\n",
      "         50%       0.00      0.00      0.00         1\n",
      "          6%       0.00      0.00      0.00        20\n",
      "          7%       0.00      0.00      0.00        20\n",
      "          8%       0.00      0.00      0.00        13\n",
      "          9%       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.75       953\n",
      "   macro avg       0.03      0.04      0.03       953\n",
      "weighted avg       0.56      0.75      0.64       953\n",
      "\n",
      "==================================================\n",
      "Effect: anxious\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.74      1.00      0.85       709\n",
      "          1%       0.00      0.00      0.00        12\n",
      "         10%       0.00      0.00      0.00         5\n",
      "        100%       0.00      0.00      0.00         2\n",
      "         11%       0.00      0.00      0.00         8\n",
      "         12%       0.00      0.00      0.00        10\n",
      "         13%       0.00      0.00      0.00         1\n",
      "         14%       0.00      0.00      0.00         7\n",
      "         15%       0.00      0.00      0.00         2\n",
      "         16%       0.00      0.00      0.00         5\n",
      "          2%       0.00      0.00      0.00        30\n",
      "         20%       0.00      0.00      0.00         4\n",
      "         21%       0.00      0.00      0.00         2\n",
      "         22%       0.00      0.00      0.00         1\n",
      "         25%       0.00      0.00      0.00         7\n",
      "          3%       0.00      0.00      0.00        30\n",
      "         31%       0.00      0.00      0.00         1\n",
      "         33%       0.00      0.00      0.00         2\n",
      "          4%       0.00      0.00      0.00        46\n",
      "          5%       0.00      0.00      0.00        20\n",
      "         50%       0.00      0.00      0.00         2\n",
      "          6%       0.00      0.00      0.00        13\n",
      "          7%       0.00      0.00      0.00        14\n",
      "          8%       0.00      0.00      0.00        10\n",
      "          9%       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.74       953\n",
      "   macro avg       0.03      0.04      0.03       953\n",
      "weighted avg       0.55      0.74      0.63       953\n",
      "\n",
      "==================================================\n",
      "Effect: stress\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.50      1.00      0.67       476\n",
      "         10%       0.00      0.00      0.00         1\n",
      "        100%       0.00      0.00      0.00        10\n",
      "         11%       0.00      0.00      0.00         2\n",
      "         12%       0.00      0.00      0.00         5\n",
      "         13%       0.00      0.00      0.00         1\n",
      "         14%       0.00      0.00      0.00         3\n",
      "         15%       0.00      0.00      0.00         5\n",
      "         16%       0.00      0.00      0.00         5\n",
      "         17%       0.00      0.00      0.00         4\n",
      "         18%       0.00      0.00      0.00         5\n",
      "         19%       0.00      0.00      0.00         2\n",
      "         20%       0.00      0.00      0.00        18\n",
      "         21%       0.00      0.00      0.00         3\n",
      "         22%       0.00      0.00      0.00        10\n",
      "         23%       0.00      0.00      0.00         5\n",
      "         24%       0.00      0.00      0.00         7\n",
      "         25%       0.00      0.00      0.00        18\n",
      "         26%       0.00      0.00      0.00        12\n",
      "         27%       0.00      0.00      0.00        10\n",
      "         28%       0.00      0.00      0.00        13\n",
      "         29%       0.00      0.00      0.00        11\n",
      "          3%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00        16\n",
      "         31%       0.00      0.00      0.00         7\n",
      "         32%       0.00      0.00      0.00        13\n",
      "         33%       0.00      0.00      0.00        40\n",
      "         34%       0.00      0.00      0.00        15\n",
      "         35%       0.00      0.00      0.00        17\n",
      "         36%       0.00      0.00      0.00        16\n",
      "         37%       0.00      0.00      0.00        15\n",
      "         38%       0.00      0.00      0.00        16\n",
      "         39%       0.00      0.00      0.00         9\n",
      "         40%       0.00      0.00      0.00        30\n",
      "         41%       0.00      0.00      0.00         9\n",
      "         42%       0.00      0.00      0.00         9\n",
      "         43%       0.00      0.00      0.00         6\n",
      "         44%       0.00      0.00      0.00         4\n",
      "         45%       0.00      0.00      0.00         4\n",
      "         46%       0.00      0.00      0.00         3\n",
      "         47%       0.00      0.00      0.00         4\n",
      "         48%       0.00      0.00      0.00         4\n",
      "         50%       0.00      0.00      0.00        40\n",
      "         51%       0.00      0.00      0.00         1\n",
      "         52%       0.00      0.00      0.00         4\n",
      "         53%       0.00      0.00      0.00         3\n",
      "         54%       0.00      0.00      0.00         4\n",
      "         55%       0.00      0.00      0.00         2\n",
      "         56%       0.00      0.00      0.00         1\n",
      "         57%       0.00      0.00      0.00         3\n",
      "          6%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         3\n",
      "         62%       0.00      0.00      0.00         1\n",
      "         63%       0.00      0.00      0.00         2\n",
      "         66%       0.00      0.00      0.00        10\n",
      "          7%       0.00      0.00      0.00         4\n",
      "         71%       0.00      0.00      0.00         1\n",
      "         77%       0.00      0.00      0.00         1\n",
      "          8%       0.00      0.00      0.00         2\n",
      "         80%       0.00      0.00      0.00         3\n",
      "         83%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.25      0.50      0.33       953\n",
      "\n",
      "==================================================\n",
      "Effect: pain\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.58      1.00      0.73       548\n",
      "         10%       0.00      0.00      0.00         2\n",
      "        100%       0.00      0.00      0.00         7\n",
      "         11%       0.00      0.00      0.00         7\n",
      "         12%       0.00      0.00      0.00         7\n",
      "         13%       0.00      0.00      0.00        10\n",
      "         14%       0.00      0.00      0.00         6\n",
      "         15%       0.00      0.00      0.00         6\n",
      "         16%       0.00      0.00      0.00         9\n",
      "         17%       0.00      0.00      0.00         9\n",
      "         18%       0.00      0.00      0.00        13\n",
      "         19%       0.00      0.00      0.00         8\n",
      "         20%       0.00      0.00      0.00        21\n",
      "         21%       0.00      0.00      0.00         5\n",
      "         22%       0.00      0.00      0.00        19\n",
      "         23%       0.00      0.00      0.00        10\n",
      "         24%       0.00      0.00      0.00        10\n",
      "         25%       0.00      0.00      0.00        24\n",
      "         26%       0.00      0.00      0.00        10\n",
      "         27%       0.00      0.00      0.00         9\n",
      "         28%       0.00      0.00      0.00        14\n",
      "         29%       0.00      0.00      0.00        14\n",
      "          3%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00        12\n",
      "         31%       0.00      0.00      0.00        10\n",
      "         32%       0.00      0.00      0.00         9\n",
      "         33%       0.00      0.00      0.00        21\n",
      "         34%       0.00      0.00      0.00         8\n",
      "         35%       0.00      0.00      0.00         8\n",
      "         36%       0.00      0.00      0.00         8\n",
      "         37%       0.00      0.00      0.00        10\n",
      "         38%       0.00      0.00      0.00         5\n",
      "         39%       0.00      0.00      0.00         3\n",
      "         40%       0.00      0.00      0.00        13\n",
      "         41%       0.00      0.00      0.00         5\n",
      "         42%       0.00      0.00      0.00         6\n",
      "         43%       0.00      0.00      0.00         1\n",
      "         44%       0.00      0.00      0.00         7\n",
      "         46%       0.00      0.00      0.00         2\n",
      "         47%       0.00      0.00      0.00         1\n",
      "         48%       0.00      0.00      0.00         2\n",
      "         49%       0.00      0.00      0.00         1\n",
      "         50%       0.00      0.00      0.00        23\n",
      "         53%       0.00      0.00      0.00         2\n",
      "         54%       0.00      0.00      0.00         3\n",
      "         55%       0.00      0.00      0.00         1\n",
      "         57%       0.00      0.00      0.00         2\n",
      "         58%       0.00      0.00      0.00         1\n",
      "          6%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         3\n",
      "         63%       0.00      0.00      0.00         1\n",
      "         64%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         4\n",
      "          7%       0.00      0.00      0.00         7\n",
      "         75%       0.00      0.00      0.00         1\n",
      "         80%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.33      0.58      0.42       953\n",
      "\n",
      "==================================================\n",
      "Effect: depression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.50      1.00      0.67       478\n",
      "         10%       0.00      0.00      0.00         6\n",
      "        100%       0.00      0.00      0.00        12\n",
      "         11%       0.00      0.00      0.00        10\n",
      "         12%       0.00      0.00      0.00         6\n",
      "         13%       0.00      0.00      0.00         6\n",
      "         14%       0.00      0.00      0.00         9\n",
      "         15%       0.00      0.00      0.00         5\n",
      "         16%       0.00      0.00      0.00        19\n",
      "         17%       0.00      0.00      0.00         7\n",
      "         18%       0.00      0.00      0.00         6\n",
      "         19%       0.00      0.00      0.00         4\n",
      "         20%       0.00      0.00      0.00        33\n",
      "         21%       0.00      0.00      0.00        18\n",
      "         22%       0.00      0.00      0.00        24\n",
      "         23%       0.00      0.00      0.00        16\n",
      "         24%       0.00      0.00      0.00        16\n",
      "         25%       0.00      0.00      0.00        36\n",
      "         26%       0.00      0.00      0.00        13\n",
      "         27%       0.00      0.00      0.00        15\n",
      "         28%       0.00      0.00      0.00        18\n",
      "         29%       0.00      0.00      0.00         8\n",
      "          3%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00        15\n",
      "         31%       0.00      0.00      0.00         8\n",
      "         32%       0.00      0.00      0.00         9\n",
      "         33%       0.00      0.00      0.00        38\n",
      "         34%       0.00      0.00      0.00         4\n",
      "         35%       0.00      0.00      0.00        14\n",
      "         36%       0.00      0.00      0.00         5\n",
      "         37%       0.00      0.00      0.00         7\n",
      "         38%       0.00      0.00      0.00         2\n",
      "         39%       0.00      0.00      0.00         1\n",
      "         40%       0.00      0.00      0.00        11\n",
      "         41%       0.00      0.00      0.00         1\n",
      "         42%       0.00      0.00      0.00         6\n",
      "         43%       0.00      0.00      0.00         2\n",
      "         44%       0.00      0.00      0.00         3\n",
      "         45%       0.00      0.00      0.00         3\n",
      "         46%       0.00      0.00      0.00         3\n",
      "         50%       0.00      0.00      0.00        26\n",
      "         54%       0.00      0.00      0.00         1\n",
      "         55%       0.00      0.00      0.00         1\n",
      "          6%       0.00      0.00      0.00         2\n",
      "         60%       0.00      0.00      0.00         4\n",
      "         62%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         6\n",
      "          7%       0.00      0.00      0.00         6\n",
      "         75%       0.00      0.00      0.00         3\n",
      "          8%       0.00      0.00      0.00         2\n",
      "         80%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.50       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.25      0.50      0.34       953\n",
      "\n",
      "==================================================\n",
      "Effect: anxiety\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.59      1.00      0.75       566\n",
      "         10%       0.00      0.00      0.00         2\n",
      "        100%       0.00      0.00      0.00        11\n",
      "         11%       0.00      0.00      0.00         1\n",
      "         12%       0.00      0.00      0.00         8\n",
      "         13%       0.00      0.00      0.00         2\n",
      "         14%       0.00      0.00      0.00         5\n",
      "         15%       0.00      0.00      0.00         6\n",
      "         16%       0.00      0.00      0.00        13\n",
      "         17%       0.00      0.00      0.00         8\n",
      "         18%       0.00      0.00      0.00         7\n",
      "         19%       0.00      0.00      0.00         6\n",
      "         20%       0.00      0.00      0.00        19\n",
      "         21%       0.00      0.00      0.00        12\n",
      "         22%       0.00      0.00      0.00        14\n",
      "         23%       0.00      0.00      0.00        12\n",
      "         24%       0.00      0.00      0.00        16\n",
      "         25%       0.00      0.00      0.00        22\n",
      "         26%       0.00      0.00      0.00        18\n",
      "         27%       0.00      0.00      0.00        21\n",
      "         28%       0.00      0.00      0.00        20\n",
      "         29%       0.00      0.00      0.00        16\n",
      "         30%       0.00      0.00      0.00        11\n",
      "         31%       0.00      0.00      0.00        12\n",
      "         32%       0.00      0.00      0.00         9\n",
      "         33%       0.00      0.00      0.00        19\n",
      "         34%       0.00      0.00      0.00         1\n",
      "         35%       0.00      0.00      0.00         6\n",
      "         36%       0.00      0.00      0.00         5\n",
      "         37%       0.00      0.00      0.00         6\n",
      "         38%       0.00      0.00      0.00         3\n",
      "         39%       0.00      0.00      0.00         2\n",
      "         40%       0.00      0.00      0.00        11\n",
      "         41%       0.00      0.00      0.00         6\n",
      "         42%       0.00      0.00      0.00         3\n",
      "         43%       0.00      0.00      0.00         1\n",
      "         44%       0.00      0.00      0.00         2\n",
      "         45%       0.00      0.00      0.00         3\n",
      "         46%       0.00      0.00      0.00         1\n",
      "         47%       0.00      0.00      0.00         1\n",
      "         50%       0.00      0.00      0.00        23\n",
      "         52%       0.00      0.00      0.00         2\n",
      "         57%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         4\n",
      "         62%       0.00      0.00      0.00         1\n",
      "         64%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         2\n",
      "          7%       0.00      0.00      0.00         1\n",
      "         75%       0.00      0.00      0.00         2\n",
      "         77%       0.00      0.00      0.00         1\n",
      "          8%       0.00      0.00      0.00         4\n",
      "         83%       0.00      0.00      0.00         1\n",
      "          9%       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.59       953\n",
      "   macro avg       0.01      0.02      0.01       953\n",
      "weighted avg       0.35      0.59      0.44       953\n",
      "\n",
      "==================================================\n",
      "Effect: insomnia\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0%       0.78      1.00      0.87       740\n",
      "         10%       0.00      0.00      0.00         3\n",
      "        100%       0.00      0.00      0.00         3\n",
      "         11%       0.00      0.00      0.00         7\n",
      "         12%       0.00      0.00      0.00         4\n",
      "         13%       0.00      0.00      0.00         6\n",
      "         14%       0.00      0.00      0.00         7\n",
      "         15%       0.00      0.00      0.00         4\n",
      "         16%       0.00      0.00      0.00        16\n",
      "         17%       0.00      0.00      0.00         7\n",
      "         18%       0.00      0.00      0.00         6\n",
      "         19%       0.00      0.00      0.00        10\n",
      "         20%       0.00      0.00      0.00        17\n",
      "         21%       0.00      0.00      0.00         7\n",
      "         22%       0.00      0.00      0.00         6\n",
      "         23%       0.00      0.00      0.00         3\n",
      "         24%       0.00      0.00      0.00         5\n",
      "         25%       0.00      0.00      0.00        15\n",
      "         26%       0.00      0.00      0.00         6\n",
      "         27%       0.00      0.00      0.00         3\n",
      "         28%       0.00      0.00      0.00         8\n",
      "         29%       0.00      0.00      0.00         2\n",
      "          3%       0.00      0.00      0.00         1\n",
      "         30%       0.00      0.00      0.00         6\n",
      "         31%       0.00      0.00      0.00         5\n",
      "         32%       0.00      0.00      0.00         3\n",
      "         33%       0.00      0.00      0.00        10\n",
      "         35%       0.00      0.00      0.00         3\n",
      "         36%       0.00      0.00      0.00         1\n",
      "         37%       0.00      0.00      0.00         2\n",
      "         38%       0.00      0.00      0.00         1\n",
      "         39%       0.00      0.00      0.00         1\n",
      "         40%       0.00      0.00      0.00         6\n",
      "         42%       0.00      0.00      0.00         2\n",
      "         44%       0.00      0.00      0.00         3\n",
      "         45%       0.00      0.00      0.00         2\n",
      "          5%       0.00      0.00      0.00         1\n",
      "         50%       0.00      0.00      0.00        13\n",
      "         55%       0.00      0.00      0.00         1\n",
      "         57%       0.00      0.00      0.00         1\n",
      "          6%       0.00      0.00      0.00         1\n",
      "         60%       0.00      0.00      0.00         1\n",
      "         66%       0.00      0.00      0.00         1\n",
      "          7%       0.00      0.00      0.00         2\n",
      "          9%       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.78       953\n",
      "   macro avg       0.02      0.02      0.02       953\n",
      "weighted avg       0.60      0.78      0.68       953\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load and preprocess data\n",
    "csv_url = 'https://raw.githubusercontent.com/zeroday-zaddy/cs422-project/c067b005a7f9a90ae114357cfe7948ed828dc07a/data/leafly_strain_data.csv'\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "# Drop rows where 'name' is blank\n",
    "df = df.dropna(subset=['name'])\n",
    "\n",
    "# Handling missing values\n",
    "df[['happy', 'euphoric', 'uplifted', 'sleepy', 'dry_mouth', 'dry_eyes', 'dizzy', 'paranoid', 'anxious', 'stress', 'pain', 'depression', 'anxiety', 'insomnia']] = df[['happy', 'euphoric', 'uplifted', 'sleepy', 'dry_mouth', 'dry_eyes', 'dizzy', 'paranoid', 'anxious', 'stress', 'pain', 'depression', 'anxiety', 'insomnia']].fillna(0)\n",
    "\n",
    "# Extract features (X) and target variables (y)\n",
    "X = df[['most_common_terpene']]\n",
    "y = df[['relaxed', 'happy', 'euphoric', 'uplifted', 'sleepy', 'dry_mouth', 'dry_eyes', 'dizzy', 'paranoid', 'anxious', 'stress', 'pain', 'depression', 'anxiety', 'insomnia']]\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(X[['most_common_terpene']])\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a machine learning model using MultiOutputClassifier\n",
    "base_classifier = DecisionTreeClassifier(random_state=42)\n",
    "model = MultiOutputClassifier(base_classifier)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance for each target variable\n",
    "for i, effect in enumerate(y.columns):\n",
    "    print(f\"Effect: {effect}\")\n",
    "    print(classification_report(y_test[effect], y_pred[:, i], zero_division='warn'))\n",
    "    print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model based on Random Forest & Decision Tree\n",
    "#Cross Validation Included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.226\n",
      "Accuracy on test set: 0.222\n",
      "Cross-validated accuracy: 0.213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load your marijuana project data from a CSV file\n",
    "# Replace 'marijuana_data.csv' with the actual path to your CSV file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zeroday-zaddy/cs422-project/main/data/strains_cleaned.csv')\n",
    "\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Assuming 'Target' is the name of your target column\n",
    "X = df['Terpene']\n",
    "y = df['Main_Effect']\n",
    "\n",
    "# One-hot encode categorical columns in X\n",
    "# Replace 'categorical_columns' with the actual names of your categorical columns\n",
    "categorical_columns = ['Main_Effect', 'Terpene']\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, random_state=42)\n",
    "#---------------------------------------------\n",
    "# Create and train Random Forest Classifier\n",
    "model = make_pipeline(SimpleImputer(strategy='mean'), RandomForestClassifier(random_state=0))\n",
    "\n",
    "# Create and train the Decision Tree Classifier\n",
    "#tree = DecisionTreeClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "#-----------------------------------------------\n",
    "print(\"Accuracy on training set: {:.3f}\".format(model.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(model.score(X_test, y_test)))\n",
    "\n",
    "# Example of using cross-validation to get a more reliable estimate\n",
    "cv_scores = cross_val_score(model, X_encoded, y, cv=5)\n",
    "print(\"Cross-validated accuracy: {:.3f}\".format(cv_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Example using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.236\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Aroused       0.00      0.00      0.00         5\n",
      "    Creative       0.00      0.00      0.00         5\n",
      "   Energetic       0.33      0.25      0.29        20\n",
      "    Euphoric       0.00      0.00      0.00        10\n",
      "     Focused       0.00      0.00      0.00         7\n",
      "      Giggly       0.00      0.00      0.00        10\n",
      "       Happy       0.00      0.00      0.00         7\n",
      "      Hungry       0.00      0.00      0.00        11\n",
      "     Relaxed       0.00      0.00      0.00        17\n",
      "      Sleepy       0.22      0.97      0.36        30\n",
      "   Talkative       0.00      0.00      0.00         7\n",
      "      Tingly       0.00      0.00      0.00         7\n",
      "    Uplifted       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.24       144\n",
      "   macro avg       0.04      0.09      0.05       144\n",
      "weighted avg       0.09      0.24      0.12       144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Regin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Regin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Regin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load your marijuana project data from a CSV file\n",
    "# Replace 'marijuana_data.csv' with the actual path to your CSV file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zeroday-zaddy/cs422-project/main/data/strains_cleaned.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Assuming 'Target' is the name of your target column\n",
    "X = df['Terpene']\n",
    "y = df['Main_Effect']\n",
    "\n",
    "# One-hot encode categorical columns in X\n",
    "# Replace 'categorical_columns' with the actual names of your categorical columns\n",
    "categorical_columns = ['Main_Effect', 'Terpene']\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_columns)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=0, max_iter=1000)\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = logreg_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set: {:.3f}\".format(accuracy))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest using more X features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.3263888888888889\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Aroused       0.00      0.00      0.00         5\n",
      "    Creative       0.00      0.00      0.00         5\n",
      "   Energetic       0.54      0.70      0.61        20\n",
      "    Euphoric       0.25      0.20      0.22        10\n",
      "     Focused       0.00      0.00      0.00         7\n",
      "      Giggly       0.00      0.00      0.00        10\n",
      "       Happy       0.00      0.00      0.00         7\n",
      "      Hungry       0.00      0.00      0.00        11\n",
      "     Relaxed       0.27      0.18      0.21        17\n",
      "      Sleepy       0.49      0.83      0.62        30\n",
      "   Talkative       0.00      0.00      0.00         7\n",
      "      Tingly       0.20      0.14      0.17         7\n",
      "    Uplifted       0.33      0.25      0.29         8\n",
      "\n",
      "    accuracy                           0.33       144\n",
      "   macro avg       0.16      0.18      0.16       144\n",
      "weighted avg       0.25      0.33      0.28       144\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zeroday-zaddy/cs422-project/main/data/strains_cleaned.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X_columns = ['Type', 'Rating', 'Num_Reviews', 'THC%', 'Other_Cannabinoids', 'Terpene']\n",
    "y_column = 'Main_Effect'\n",
    "\n",
    "X = df[X_columns]\n",
    "y = df[y_column]\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create and train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example using Binary Classification to determine if Main Effect is Sleepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8194444444444444\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88       114\n",
      "           1       0.56      0.63      0.59        30\n",
      "\n",
      "    accuracy                           0.82       144\n",
      "   macro avg       0.73      0.75      0.74       144\n",
      "weighted avg       0.83      0.82      0.82       144\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Regin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/zeroday-zaddy/cs422-project/main/data/strains_cleaned.csv')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Define features (X) and binary target variable (y)\n",
    "X_columns = ['Type', 'Rating', 'Num_Reviews', 'THC%', 'Other_Cannabinoids', 'Terpene']\n",
    "y_column = 'Main_Effect'\n",
    "\n",
    "# Binary classification: 1 if Main_Effect is \"Sleepy\", 0 otherwise\n",
    "df['Binary_Target'] = (df[y_column] == 'Sleepy').astype(int)\n",
    "\n",
    "X = df[X_columns]\n",
    "y = df['Binary_Target']\n",
    "\n",
    "# Encode categorical variables\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, stratify=y, random_state=42)\n",
    "\n",
    "# Create and train a Logistic Regression model\n",
    "logistic_regression = LogisticRegression(random_state=42)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy on test set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
